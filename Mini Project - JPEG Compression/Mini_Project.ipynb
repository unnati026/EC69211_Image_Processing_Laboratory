{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I9RDwXjZi36M"
   },
   "source": [
    "# Image and Video Processing Lab\n",
    "<center>\n",
    "<h2>Mini Project - JPEG Compression</h2>\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "<h3> Submitted by:<h3>\n",
    "<h4> Sneha Dash (21EC39023), Unnati Singh (21EC39027) </h4></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MZIhlNQjmt5J"
   },
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QkciFnMxmwYi"
   },
   "source": [
    "### Importing the required packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "A6HYVzB4H0AB"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pickle\n",
    "import gzip\n",
    "\n",
    "from collections import Counter\n",
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tB6zfl2KqpNs"
   },
   "source": [
    "## JPEG Compression Pipeline:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "csjEcqxSqurZ"
   },
   "source": [
    "### Reading Image in RGB format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "pOoIz6ADH0AE"
   },
   "outputs": [],
   "source": [
    "def read_image(imagepath):\n",
    "    image_bgr = cv2.imread(imagepath)\n",
    "    image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    return image_rgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XrSx3gzcq-bg"
   },
   "source": [
    "### Colour Space conversion to YCbCr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sNYv0KnYlUHb"
   },
   "source": [
    "The following function converts an RGB image to the YCbCr color space using a standard transformation matrix. This conversion is commonly used in image and video compression.\n",
    "\n",
    "- **Parameters**:\n",
    "  - **image**: A NumPy array representing the RGB image, with pixel values in the range [0, 255].\n",
    "\n",
    "- **Returns**:\n",
    "  - **ycbcr_image**: A NumPy array representing the image in YCbCr color space, with pixel values clipped to the range [0, 255] and cast to `uint8`.\n",
    "\n",
    "**Process**:\n",
    "\n",
    "The function uses the following matrix transformation to convert RGB to YCbCr:\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "Y \\\\\n",
    "Cb \\\\\n",
    "Cr\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "0.299 & 0.587 & 0.114 \\\\\n",
    "-0.168736 & -0.331264 & 0.5 \\\\\n",
    "0.5 & -0.418688 & -0.081312\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "R \\\\\n",
    "G \\\\\n",
    "B\n",
    "\\end{bmatrix}\n",
    "+\n",
    "\\begin{bmatrix}\n",
    "0 \\\\\n",
    "128 \\\\\n",
    "128\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "This formula adjusts the RGB channels to separate luminance (Y) and chrominance (Cb, Cr) components.\n",
    "\n",
    "The result is clipped to ensure the values remain within the valid range for image data [0, 255].\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "wR8Y2A-NH0AF"
   },
   "outputs": [],
   "source": [
    "def rgb_to_ycbcr(image):\n",
    "    conversion_matrix = np.array([[ 0.299,  0.587,  0.114],\n",
    "                                  [-0.168736, -0.331264,  0.5],\n",
    "                                  [ 0.5, -0.418688, -0.081312]])\n",
    "\n",
    "    offset = np.array([0, 128, 128])\n",
    "    ycbcr_image = np.dot(image, conversion_matrix.T) + offset\n",
    "\n",
    "    return np.clip(ycbcr_image, 0, 255).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sa0Rqz3SrCry"
   },
   "source": [
    "### Subsampling:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dDRt4j_vpPPg"
   },
   "source": [
    "This function performs chroma subsampling on a YCbCr image by downsampling the chrominance channels (Cb and Cr) based on specified horizontal and vertical ratios. This is often used in image and video compression to reduce the amount of chrominance data while maintaining luminance (Y) quality.\n",
    "\n",
    "- **Parameters**:\n",
    "  - **ycbcr_image**: A NumPy array representing the YCbCr image.\n",
    "  - **ratio1h**, **ratio1v**: Horizontal and vertical subsampling ratios for the Cb (blue-difference) channel.\n",
    "  - **ratio2h**, **ratio2v**: Horizontal and vertical subsampling ratios for the Cr (red-difference) channel.\n",
    "\n",
    "- **Returns**:\n",
    "  - **Y**: The luminance channel (Y), unchanged.\n",
    "  - **Cb**: The subsampled blue-difference channel (Cb).\n",
    "  - **Cr**: The subsampled red-difference channel (Cr).\n",
    "\n",
    "**Process**:\n",
    "The function slices the Cb and Cr channels based on the specified horizontal and vertical subsampling ratios, reducing their resolution, while the luminance channel (Y) is retained at full resolution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "L1uawuYTH0AG"
   },
   "outputs": [],
   "source": [
    "def chroma_subsampling(ycbcr_image, ratio1h = 2, ratio1v = 2, ratio2h = 2, ratio2v = 2):\n",
    "    Y = ycbcr_image[:, :, 0]\n",
    "    Cb = ycbcr_image[::ratio1h, ::ratio1v, 1]\n",
    "    Cr = ycbcr_image[::ratio2h, ::ratio2v, 2]\n",
    "\n",
    "    return Y, Cb, Cr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QMTMCNnBrEio"
   },
   "source": [
    "### Formation of 8Ã—8 blocks for processing:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X0tLew0Upchs"
   },
   "source": [
    "This function divides a single-channel image (such as Y, Cb, or Cr) into non-overlapping square blocks of a specified size (default is 8x8). This step is commonly used in image compression algorithms like JPEG.\n",
    "\n",
    "- **Parameters**:\n",
    "  - **channel**: A 2D NumPy array representing a single-channel image (e.g., luminance or chrominance).\n",
    "  - **block_size**: The size of each block (default is 8).\n",
    "\n",
    "- **Returns**:\n",
    "  - **blocks**: A 3D NumPy array where each slice along the first dimension is a flattened `block_size x block_size` block from the original image.\n",
    "\n",
    "**Process**:\n",
    "1. The function ensures that the image dimensions are divisible by the block size by trimming any extra pixels.\n",
    "2. The image is then reshaped into smaller blocks, where each block is a non-overlapping sub-region of size `block_size x block_size`.\n",
    "3. The blocks are flattened and returned as a 3D array of shape `(num_blocks, block_size, block_size)`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "NxV3n6E5H0AG"
   },
   "outputs": [],
   "source": [
    "def block_formation(channel, block_size=8):\n",
    "    h, w = channel.shape\n",
    "    h -= h % block_size\n",
    "    w -= w % block_size\n",
    "    channel = channel[:h, :w]\n",
    "\n",
    "    blocks = (channel.reshape(h // block_size, block_size, -1, block_size).swapaxes(1, 2).reshape(-1, block_size, block_size))\n",
    "\n",
    "    return blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ItzDbD2asHR-"
   },
   "source": [
    "### Performing DCT on channel blocks:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HpbHpywRqzQc"
   },
   "source": [
    "We apply the Discrete Cosine Transform (DCT) to a given square block, commonly used in image compression to convert spatial data into frequency components.\n",
    "\n",
    "- **Parameters**:\n",
    "  - **block**: A 2D NumPy array representing an $N \\times N$ block of pixel values.\n",
    "\n",
    "- **Returns**:\n",
    "  - **dct_matrix**: A 2D NumPy array of DCT coefficients for the input block.\n",
    "\n",
    "The DCT formula applied here is:\n",
    "\n",
    "$$\n",
    "DCT(u, v) = \\frac{1}{4} \\, C(u) C(v) \\sum_{x=0}^{N-1} \\sum_{y=0}^{N-1} \\text{block}[x, y] \\cos \\left(\\frac{(2x + 1) u \\pi}{2N}\\right) \\cos \\left(\\frac{(2y + 1) v \\pi}{2N}\\right)\n",
    "$$\n",
    "\n",
    "where $C(u) = \\frac{1}{\\sqrt{2}}$ if $u = 0$ (and similarly for $C(v)$), otherwise $C(u) = 1$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "oF_3oKQZH0AG"
   },
   "outputs": [],
   "source": [
    "def dct_block(block):\n",
    "    N = block.shape[0]\n",
    "\n",
    "    u = np.arange(N)\n",
    "    v = np.arange(N)\n",
    "\n",
    "    cos_u = np.cos((2 * np.outer(np.arange(N), u) + 1) * np.pi / (2 * N))\n",
    "    cos_v = np.cos((2 * np.outer(np.arange(N), v) + 1) * np.pi / (2 * N))\n",
    "\n",
    "    cu = np.where(u == 0, 1 / np.sqrt(2), 1)\n",
    "    cv = np.where(v == 0, 1 / np.sqrt(2), 1)\n",
    "\n",
    "    dct_matrix = 0.25 * (cu[:, None] * cv[None, :] * np.sum(block * cos_u[:, :, None] * cos_v[:, None, :], axis=(0, 1)))\n",
    "\n",
    "    return dct_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cmQj92ScsLgz"
   },
   "source": [
    "### Quantising:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6oBtszjrG9mv"
   },
   "source": [
    "Then we quantize a DCT-transformed block by dividing each element by a corresponding element in a quantization matrix, then rounding to the nearest integer. This step is crucial in image compression to reduce precision and data size.\n",
    "\n",
    "- **Parameters**:\n",
    "  - **block**: A 2D NumPy array representing a DCT-transformed block.\n",
    "  - **quant_matrix**: A 2D NumPy array (of the same size as `block`) used for quantization.\n",
    "\n",
    "- **Returns**:\n",
    "  - A 2D NumPy array of quantized DCT coefficients as integers.\n",
    "  \n",
    "The quantization formula is:\n",
    "\n",
    "$$\n",
    "\\mathrm{quantized\\_block} = \\mathrm{round}\\left(\\frac{\\mathrm{block}}{\\mathrm{quant\\_matrix}}\\right)\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "iJGDSOLXH0AH"
   },
   "outputs": [],
   "source": [
    "def quantize(block, quant_matrix):\n",
    "    return np.round(block / quant_matrix).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Ljb27oosNe4"
   },
   "source": [
    "### Run Length encoding:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G8qbq3FyHZpa"
   },
   "source": [
    "This function performs run-length encoding (RLE) on a DCT-transformed block. The function first arranges the block's elements in a zigzag order to prioritize lower-frequency components, then encodes sequences of zeros to achieve data compression.\n",
    "\n",
    "- **Parameters**:\n",
    "  - **block**: A 2D NumPy array representing a quantized DCT block.\n",
    "\n",
    "- **Returns**:\n",
    "  - **rle**: A list where non-zero values are directly listed, and sequences of zeros are represented as tuples `(zeros, value)`, where `zeros` is the count of consecutive zeros before `value`.\n",
    "\n",
    "### Process:\n",
    "\n",
    "1. **Zigzag Scan**: The block's elements are reordered in a zigzag pattern to prioritize lower-frequency components (top-left to bottom-right, following a diagonal pattern).\n",
    "   \n",
    "   The zigzag pattern is defined as:\n",
    "\n",
    "   $$\n",
    "   \\text{zigzag\\_order} = \\left[ (0, 0), (0, 1), (1, 0), (2, 0), (1, 1), (0, 2), \\dots \\right]\n",
    "   $$\n",
    "\n",
    "2. **Run-Length Encoding**:\n",
    "   - Sequences of consecutive zeros are encoded as a tuple `(number of zeros, next non-zero value)`.\n",
    "   - Non-zero values are stored as they are.\n",
    "\n",
    "   Example:\n",
    "   - For a zigzag scan like `[0, 0, 1, 0, 0, 2]`, the RLE output would be `[(2, 1), (2, 2)]`.\n",
    "\n",
    "This encoding helps compress the data by reducing the storage needed for long sequences of zeros.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "5PK_r-CZVG69"
   },
   "outputs": [],
   "source": [
    "def run_length_encode(block):\n",
    "\n",
    "    def zigzag_scan(block):\n",
    "        zigzag_order = [\n",
    "            (0, 0), (0, 1), (1, 0), (2, 0), (1, 1), (0, 2), (0, 3), (1, 2), (2, 1), (3, 0),\n",
    "            (3, 1), (2, 2), (1, 3), (0, 4), (0, 5), (1, 4), (2, 3), (3, 2), (4, 0), (5, 0),\n",
    "            (4, 1), (3, 3), (2, 4), (1, 5), (0, 6), (0, 7), (1, 6), (2, 5), (3, 4), (4, 3),\n",
    "            (5, 1), (6, 0), (7, 0), (6, 1), (5, 2), (4, 4), (3, 5), (2, 6), (1, 7), (0, 7),\n",
    "            (1, 6), (2, 5), (3, 4), (4, 3), (5, 1), (6, 0), (7, 0), (6, 1), (5, 2), (4, 4),\n",
    "            (3, 5), (2, 6), (1, 7), (0, 7)\n",
    "        ]\n",
    "        return [block[x, y] for x, y in zigzag_order]\n",
    "\n",
    "    zigzag_values = zigzag_scan(block)\n",
    "\n",
    "    rle = []\n",
    "    zeros = 0\n",
    "    for value in zigzag_values:\n",
    "        if value == 0:\n",
    "            zeros += 1\n",
    "        else:\n",
    "            if zeros > 0:\n",
    "                rle.append((zeros, value))\n",
    "                zeros = 0\n",
    "            else:\n",
    "                rle.append(value)\n",
    "    return rle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MQTkCxWMsQla"
   },
   "source": [
    "### Huffman Encoding:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nzzam2PeHpLX"
   },
   "source": [
    "Finally, we perform Huffman coding on the input data, which is typically a run-length encoded (RLE) sequence. The function builds a Huffman tree based on symbol frequencies, then generates the corresponding binary codes for each symbol to compress the data.\n",
    "\n",
    "- **Parameters**:\n",
    "  - **rle_data**: A list of symbols (e.g., from run-length encoding) that need to be compressed using Huffman coding.\n",
    "\n",
    "- **Returns**:\n",
    "  - **codes**: A dictionary mapping each symbol to its Huffman binary code.\n",
    "  - **encoded_sequence**: A string representing the input data encoded using the generated Huffman codes.\n",
    "\n",
    "### Process:\n",
    "\n",
    "1. **Frequency Calculation**: The function first calculates the frequency of each symbol in the input `rle_data` using the `Counter` from the `collections` module.\n",
    "   \n",
    "2. **Tree Construction**: The Huffman tree is built using the following steps:\n",
    "   - Sort the symbols by frequency.\n",
    "   - Combine the two least frequent symbols into a new node, and repeat until only one node remains.\n",
    "\n",
    "3. **Huffman Code Generation**: Starting from the root of the Huffman tree, assign binary codes:\n",
    "   - Traverse left with '0' and right with '1' to generate codes for each symbol.\n",
    "\n",
    "4. **Encoding**: The input sequence is then encoded by replacing each symbol with its corresponding Huffman code.\n",
    "\n",
    "This method efficiently compresses data by assigning shorter codes to more frequent symbols and longer codes to less frequent symbols.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "v93VykBRWHQw"
   },
   "outputs": [],
   "source": [
    "def huffman(rle_data):\n",
    "    symbol_frequencies = Counter(rle_data)\n",
    "    nodes = [(symbol, freq) for symbol, freq in symbol_frequencies.items()]\n",
    "\n",
    "    def make_tree(nodes):\n",
    "        nodes = sorted(nodes, key=lambda x: x[1], reverse=True)\n",
    "        while len(nodes) > 1:\n",
    "            key1, c1 = nodes.pop()\n",
    "            key2, c2 = nodes.pop()\n",
    "            node = (key1, key2)\n",
    "            nodes.append((node, c1 + c2))\n",
    "            nodes = sorted(nodes, key=lambda x: x[1], reverse=True)\n",
    "        return nodes[0][0]\n",
    "\n",
    "    def huffman_code_tree(node, bin_string=''):\n",
    "        if isinstance(node, tuple):\n",
    "            left, right = node\n",
    "            left_code = huffman_code_tree(left, bin_string + '0')\n",
    "            right_code = huffman_code_tree(right, bin_string + '1')\n",
    "            return {**left_code, **right_code}\n",
    "        else:\n",
    "            return {node: bin_string}\n",
    "\n",
    "    tree = make_tree(nodes)\n",
    "    codes = huffman_code_tree(tree)\n",
    "\n",
    "    for symbol in set(rle_data):\n",
    "        if symbol not in codes:\n",
    "            codes[symbol] = '0'\n",
    "\n",
    "    encoded_sequence = ''.join(codes[symbol] for symbol in rle_data)\n",
    "\n",
    "    return codes, encoded_sequence\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GR6hsV5BsSup"
   },
   "source": [
    "## JPEG Compression:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8xI6TODWHuYe"
   },
   "source": [
    "The following function uses all the above defined functions to compress the given image and then saves them as a pickle file, giving a comparison between the sizes of the original image and the saved compressed file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "8A5hNglVFEjl"
   },
   "outputs": [],
   "source": [
    "def compress_save(image_path):\n",
    "\n",
    "    def compression(image_path, quality=50):\n",
    "        image_rgb = read_image(image_path)\n",
    "        ycbcr_image = rgb_to_ycbcr(image_rgb)\n",
    "\n",
    "        Y, Cb, Cr = chroma_subsampling(ycbcr_image)\n",
    "\n",
    "        quant_matrix_y = np.array([\n",
    "            [16, 11, 10, 16, 24, 40, 51, 61],\n",
    "            [12, 12, 14, 19, 26, 58, 60, 55],\n",
    "            [14, 13, 16, 24, 40, 57, 69, 56],\n",
    "            [14, 17, 22, 29, 51, 87, 80, 62],\n",
    "            [18, 22, 37, 56, 68, 109, 103, 77],\n",
    "            [24, 35, 55, 64, 81, 104, 113, 92],\n",
    "            [49, 64, 78, 87, 103, 121, 120, 101],\n",
    "            [72, 92, 95, 98, 112, 100, 103, 99]\n",
    "        ]) * (100 - quality) / 50\n",
    "\n",
    "        quant_matrix_cbcr = quant_matrix_y\n",
    "\n",
    "        def process_channel(channel, quant_matrix):\n",
    "            blocks = block_formation(channel)\n",
    "            compressed_blocks = []\n",
    "            for block in blocks:\n",
    "                dct_block_result = dct_block(block)\n",
    "                quantized_block = quantize(dct_block_result, quant_matrix)\n",
    "                rle_encoded_block = run_length_encode(quantized_block)\n",
    "                compressed_blocks.append(rle_encoded_block)\n",
    "            return compressed_blocks\n",
    "\n",
    "        compressed_Y = process_channel(Y, quant_matrix_y)\n",
    "        compressed_Cb = process_channel(Cb, quant_matrix_cbcr)\n",
    "        compressed_Cr = process_channel(Cr, quant_matrix_cbcr)\n",
    "\n",
    "        flat_compressed_Y = list(chain.from_iterable(compressed_Y))\n",
    "        flat_compressed_Cb = list(chain.from_iterable(compressed_Cb))\n",
    "        flat_compressed_Cr = list(chain.from_iterable(compressed_Cr))\n",
    "\n",
    "        _, huffman_Y = huffman(flat_compressed_Y)\n",
    "        _, huffman_Cb = huffman(flat_compressed_Cb)\n",
    "        _, huffman_Cr = huffman(flat_compressed_Cr)\n",
    "\n",
    "        complete_data = {\n",
    "            'Y': flat_compressed_Y,\n",
    "            'Cb': flat_compressed_Cb,\n",
    "            'Cr': flat_compressed_Cr,\n",
    "            'huffman_Y': huffman_Y,\n",
    "            'huffman_Cb': huffman_Cb,\n",
    "            'huffman_Cr': huffman_Cr,\n",
    "        }\n",
    "\n",
    "        compressed_data = { 'huffman_Y': huffman_Y,\n",
    "                            'huffman_Cb': huffman_Cb,\n",
    "                            'huffman_Cr': huffman_Cr,\n",
    "                            }\n",
    "\n",
    "        return complete_data, compressed_data\n",
    "\n",
    "    if not os.path.exists('output'):\n",
    "        os.makedirs('output')\n",
    "\n",
    "    pickle_file_path = \"output/\" + os.path.splitext(os.path.basename(image_path))[0] + '_bin' + '.pkl.gz'\n",
    "    picklepath2 = \"output/encoded_only\" + os.path.splitext(os.path.basename(image_path))[0] + '_bin' + '.pkl.gz'\n",
    "    binary, comp = compression(image_path)\n",
    "\n",
    "    with gzip.open(pickle_file_path, 'wb') as file:\n",
    "        pickle.dump(binary, file)\n",
    "\n",
    "    with gzip.open(picklepath2, 'wb') as file:\n",
    "        pickle.dump(comp, file)\n",
    "\n",
    "    input_image_size = os.path.getsize(image_path)\n",
    "    compressed_file_size = os.path.getsize(picklepath2)\n",
    "\n",
    "    print(f\"Compressed file saved at: {pickle_file_path}\")\n",
    "    print(f\"Original Size: {input_image_size/ (1024 ** 2):.2f} MB\")\n",
    "    print(f\"Compressed Size: {compressed_file_size/ (1024 ** 2):.2f} MB\")\n",
    "\n",
    "    return binary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kKWLwAj_Ixx1"
   },
   "source": [
    "## Running the final defined function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cN6_Pek72Kv7",
    "outputId": "d28fad96-f9d3-4ca0-9f32-79d194dde462"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compressed file saved at: output/green_bin.pkl.gz\n",
      "Original Size: 1.94 MB\n",
      "Compressed Size: 0.33 MB\n"
     ]
    }
   ],
   "source": [
    "comp = compress_save(input('Enter image path: '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y: [11, 14, 20, 17, 18, 18, 11, 18, 17, 17, 13, 16, 13, 8, 5, 10, 10, 11, 13, 10, 10, 9, 7, 5, 4, 3, 5, 5, 5, 4, 6, 5, 3, 3, 5, 4, 3, 4, 5, 3, 5, 5, 5, 4, 6, 5, 3, 3, 5, 4, 3, 4, 5, 3, 11, 14, 20, 17, 18, 18, 11, 18, 17, 17, 13, 16, 13, 8, 5, 10, 10, 11, 13, 10, 10, 9, 7, 5, 4, 3, 5, 5, 5, 4, 6, 5, 3, 3, 5, 4, 3, 4, 5, 3, 5, 5, 5, 4, 6, 5, 3, 3, 5, 4, 3, 4, 5, 3, 11, 14, 20, 17, 18, 17, 11, 18, 16, 17, 13, 15, 13, 8, 5, 10, 10, 11, 13, 10, 10, 8, 7, 4, 4, 3, 5, 5, 5, 4, 6, 5, 3, 3, 4, 4, 3, 4, 5, 3, 5, 5, 5, 4, 6, 5, 3, 3, 4, 4, 3, 4, 5, 3, 11, 14, 20, 17, 18, 17, 11, 18, 16, 17, 13, 15, 13, 8, 5, 10, 10, 11, 13, 10, 10, 9, 7, 4, 4, 3, 5, 5, 5, 4, 6, 5, 3, 3, 4, 4, 3, 4]\n",
      "Cb: [4, 5, 8, 7, 7, 7, 4, 7, 6, 7, 5, 6, 5, 3, 2, 4, 4, 4, 5, 4, 4, 3, 3, 2, 1, 1, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 1, 2, 2, 1, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 1, 2, 2, 1, 4, 5, 8, 7, 7, 7, 4, 7, 6, 7, 5, 6, 5, 3, 2, 4, 4, 4, 5, 4, 4, 3, 3, 2, 1, 1, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 1, 2, 2, 1, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 1, 2, 2, 1, 4, 5, 8, 7, 7, 7, 4, 7, 7, 7, 5, 6, 5, 3, 2, 4, 4, 4, 5, 4, 4, 3, 3, 2, 2, 1, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 1, 2, 2, 1, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 1, 2, 2, 1, 4, 5, 8, 7, 7, 7, 4, 7, 7, 7, 5, 6, 5, 3, 2, 4, 4, 4, 5, 4, 4, 3, 3, 2, 2, 1, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 1, 2]\n",
      "Cr: [8, 10, 14, 12, 13, 12, 8, 13, 12, 12, 9, 11, 9, 5, 3, 7, 7, 8, 9, 7, 7, 6, 5, 3, 3, 2, 3, 3, 4, 3, 4, 3, 2, 2, 3, 3, 2, 3, 4, 2, 3, 3, 4, 3, 4, 3, 2, 2, 3, 3, 2, 3, 4, 2, 7, 10, 14, 12, 13, 12, 8, 12, 12, 12, 9, 11, 9, 5, 3, 7, 7, 8, 9, 7, 7, 6, 5, 3, 3, 2, 3, 3, 4, 3, 4, 3, 2, 2, 3, 3, 2, 3, 4, 2, 3, 3, 4, 3, 4, 3, 2, 2, 3, 3, 2, 3, 4, 2, 8, 10, 14, 12, 13, 12, 8, 13, 12, 12, 9, 11, 9, 5, 3, 7, 7, 8, 9, 7, 7, 6, 5, 3, 3, 2, 3, 3, 4, 3, 4, 3, 2, 2, 3, 3, 2, 3, 4, 2, 3, 3, 4, 3, 4, 3, 2, 2, 3, 3, 2, 3, 4, 2, 8, 10, 14, 12, 13, 12, 8, 13, 12, 12, 9, 11, 9, 5, 3, 7, 7, 8, 9, 7, 7, 6, 5, 3, 3, 2, 3, 3, 4, 3, 4, 3, 2, 2, 3, 3, 2, 3]\n",
      "huffman_Y: 11100111111111111100110100110100010100011100101000101001101001101110101111110111010110001111101111011100101110111101111010101111010011000100100100110000010010101001100011000010100100100110000010010101\n",
      "huffman_Cb: 01001101111001110111011101001111101011101101101011000100100100100110010010000010111011101010101010101110111010101110101011101010101010101110111010101110101011100100110111100111011101110100111110101110\n",
      "huffman_Cr: 00010000100000110010110110010001011011001100101111000101111000011001001000101110010010110010000111110111110101101011101101111110111010101111101011010111011011111101110101010010000100000110010110110010\n"
     ]
    }
   ],
   "source": [
    "for key in comp:\n",
    "    print(f\"{key}: {comp[key][:200]}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
